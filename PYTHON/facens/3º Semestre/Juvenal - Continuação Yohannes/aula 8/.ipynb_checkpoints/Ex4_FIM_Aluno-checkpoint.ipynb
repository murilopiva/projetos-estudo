{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> Frequent Itemset Mining </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este exercício exploramos os dados de uma competição no Kaggle, disponível no link abaixo:\n",
    "\n",
    "https://www.kaggle.com/c/instacart-market-basket-analysis\n",
    "\n",
    "A empresa Instacart fornece serviços de compra e entrega através de um App. Entre seus objetivos estão identificar quais produtos os clientes:\n",
    "\n",
    "- Comprariam novamente;\n",
    "- Tentariam usar pela primeira vez;\n",
    "- Deixariam para a próxima compra;\n",
    "\n",
    "Usaremos a base transacional fornecida para buscar regras de associação. A idéia é buscar produtos que são frequentemente comprados em conjunto para orientar estratégias de cross-selling.\n",
    "\n",
    "Para não implementar o algoritmo do zero, a biblioteca MLxtend será aplicada. Segue abaixo o link com detalhes da sua instalação no ambiente Anaconda;\n",
    "\n",
    "https://anaconda.org/conda-forge/mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carrega cestas de compra em um dataframe. Em função do volume de dados frequentemente usaremos estratégias para reduzir o uso de memória. Neste caso carregamos apenas as colunas indispensáveis: código da compra e do produto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = r\"https://raw.githubusercontent.com/brvnl/AplicacoesAprendizadoMaquina/main/order_products__train.csv\"\n",
    "df_raw = pd.read_csv(url, usecols=[\"order_id\", \"product_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checando o número de linhas, colunas e a memória ocupada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1384617 entries, 0 to 1384616\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count    Dtype\n",
      "---  ------      --------------    -----\n",
      " 0   order_id    1384617 non-null  int64\n",
      " 1   product_id  1384617 non-null  int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 21.1 MB\n"
     ]
    }
   ],
   "source": [
    "df_raw.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando uma amostra dos dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>49302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  product_id\n",
       "0         1       49302\n",
       "1         1       11109\n",
       "2         1       10246"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando carcaterísticas do dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantas compras diferentes? 131209.\n",
      "Quantos produtos diferentes? 39123.\n"
     ]
    }
   ],
   "source": [
    "print(\"Quantas compras diferentes? %d.\" %(len(df_raw[\"order_id\"].unique())))\n",
    "print(\"Quantos produtos diferentes? %d.\" %(len(df_raw[\"product_id\"].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando tabela com nomes dos produtos e convertendo em um dicionário:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_p = r\"https://raw.githubusercontent.com/brvnl/AplicacoesAprendizadoMaquina/main/products.csv\"\n",
    "df_products_lookup = pd.read_csv(url_p)\n",
    "\n",
    "d = dict(zip(df_products_lookup[\"product_id\"], df_products_lookup[\"product_name\"]))\n",
    "del df_products_lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtrando os dados\n",
    "\n",
    "Por questão de uso de memória, pode ser necessário executar a análise por partes. Para isso, o código abaixo permite filtrar apenas compras/produtos de uma ilha ou departamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_aisle_department(df, aisle = None, department = None):\n",
    "    url = r\"https://github.com/brvnl/AplicacoesAprendizadoMaquina/blob/main/product_aisle_department_lookup.xlsx?raw=true\"\n",
    "    \n",
    "    if aisle is not None:\n",
    "        dft = pd.read_excel(url, sheet_name=\"Products\", usecols=[\"product_id\", \"aisle\"])\n",
    "        dft = pd.merge(df, dft, left_on=\"product_id\", right_on=\"product_id\")\n",
    "        dft = dft[dft[\"aisle\"].isin(aisle)]\n",
    "        dft.drop(columns=\"aisle\", inplace=True)\n",
    "        \n",
    "    elif department is not None:\n",
    "        dft = pd.read_excel(url, sheet_name=\"Products\", usecols=[\"product_id\", \"department\"])\n",
    "        dft = pd.merge(df, dft, left_on=\"product_id\", right_on=\"product_id\")\n",
    "        dft = dft[dft[\"department\"].isin(department)]\n",
    "        dft.drop(columns=\"department\", inplace=True)\n",
    "    \n",
    "    else:\n",
    "        dft = df\n",
    "    \n",
    "    print(\"Quantas compras diferentes? %d.\" %(len(dft[\"order_id\"].unique())))\n",
    "    print(\"Quantos produtos diferentes? %d.\" %(len(dft[\"product_id\"].unique())))\n",
    "    \n",
    "    return dft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Os parametros aisle e department devem ser sempre **None** ou na forma de lista (mesmo com um único elemento). \n",
    "- Na implementação atual o fitro ocorre ou por ilha ou por departamento, mas não junto. Adapte o código caso deseje o filtor duplo.\n",
    "\n",
    "Segue abaixo alguns exemplos de uso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantas compras diferentes? 14908.\n",
      "Quantos produtos diferentes? 4314.\n"
     ]
    }
   ],
   "source": [
    "url = r\"https://raw.githubusercontent.com/brvnl/AplicacoesAprendizadoMaquina/main/order_products__train.csv\"\n",
    "df_raw = pd.read_csv(url, usecols=[\"order_id\", \"product_id\"])\n",
    "\n",
    "# Ex1.: Procurando relações entre produtos nos departamentos \"personal care\", \"meat seafood\", \"missing\"\n",
    "df_raw = filter_aisle_department(df_raw, aisle = None, department = [\"personal care\"])\n",
    "\n",
    "# Ex2.: Procurando relações entre produtos na ilha de congelados\n",
    "#df_raw = filter_aisle_department(df_raw, aisle = [\"frozen meals\"], department = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajustando o layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como estamos interessados em analisar características das compras individualmente, precisamos transformar os dados de forma que cada registro represente uma ordem. Para isso vamos distribuir o **order_id** nas linhas e **product_id** nas colunas com codificação One Hot Encoding. \n",
    "\n",
    "Poderiamos usar a coluna **add_to_cart_order** como valor, mas como só nos interessa se o produto foi comprado ou não, adicionamos uma nova coluna com a flag **1** nos produtos, que irá será usada para o One Hot Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw[\"comprado\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo executamos o pivot table para obter o novo layout. Nesta etapa o uso de memória cresce bastante, passando facilmente dos 16Gb de Ram. Para controlar este comportamento, ajuste a quantidade de linhas na função _head()_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para dados full podemos filtrar pela função head.\n",
    "#df1 = df_raw.sample(40000).pivot_table(index='order_id', columns='product_id', values=\"comprado\", fill_value=0)\n",
    "\n",
    "# Caso os dados já estejam previamente filtrados podemos usar o dataframe diretamente\n",
    "df1 = df_raw.pivot_table(index='order_id', columns='product_id', values=\"comprado\", fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando quantidade de linhas, colunas e memória consumida pelo dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14908 entries, 98 to 3420857\n",
      "Columns: 4314 entries, 13 to 49688\n",
      "dtypes: int64(4314)\n",
      "memory usage: 490.8 MB\n"
     ]
    }
   ],
   "source": [
    "df1.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Caso o dataframe estaja ocupando muita memoria, execute o comando abaixo para desalocar RAM e tente uma quantidade menor de linhas no código de pivoteamento da tabela. Caso o uso de memória não diminua, reinicie o kernel do jupyter e execute o código desde o início._**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df1\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buscando regras com APRIORI\n",
    "\n",
    "A biblioteca MLxtend trabalha com a mineração de regras em duas etapas:\n",
    "\n",
    "- Na primeira são procurados conjuntos frequentes de acordo com um threshold para a métrica __suporte__.\n",
    "- Na segunda etapa são avaliados dentre os conjuntos identificados, quais atendem um threshold mínimo de uma outra variável.\n",
    "\n",
    "Mais detalhes sobre o uso da biblioteca estão disponíveis no link:\n",
    "http://rasbt.github.io/mlxtend/api_subpackages/mlxtend.frequent_patterns/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acha os conjuntos frequentes que atendem um suporte minimo (%)\n",
    "frequent_itemsets = apriori(df1, min_support=0.009)\n",
    "\n",
    "# Filtra os conjuntos pela métrica confiança\n",
    "if len(frequent_itemsets):\n",
    "    selected = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.02)\n",
    "else:\n",
    "    print(\"Não há itemsets que atendam ao mínimo suporte fornecido.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo apresentamos os resultados, trocando os códigos dos produtos por sua descrição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_from_frozenset(row):\n",
    "    return d[list(row)[0]]\n",
    "\n",
    "if len(frequent_itemsets):\n",
    "    selected[\"antecedents_name\"] = selected[\"antecedents\"].apply(int_from_frozenset)\n",
    "    selected[\"consequents_name\"] = selected[\"consequents\"].apply(int_from_frozenset)\n",
    "    selected.drop(columns=[\"antecedents\", \"consequents\"])\n",
    "else:\n",
    "    print(\"Não há itemsets que atendam ao mínimo suporte fornecido.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relações encontradas\n",
    "\n",
    "Descreva no campo abaixo as relações mais interessantes encontradas e como você chegou a elas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sua resposta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>antecedents_name</th>\n",
       "      <th>consequents_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>(211)</td>\n",
       "      <td>(110)</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.037646</td>\n",
       "      <td>0.006635</td>\n",
       "      <td>0.235897</td>\n",
       "      <td>6.266195</td>\n",
       "      <td>0.005576</td>\n",
       "      <td>1.259457</td>\n",
       "      <td>Gluten Free Organic Cereal Coconut Maple Vanilla</td>\n",
       "      <td>Uncured Turkey Bologna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>(110)</td>\n",
       "      <td>(211)</td>\n",
       "      <td>0.037646</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.006635</td>\n",
       "      <td>0.176245</td>\n",
       "      <td>6.266195</td>\n",
       "      <td>0.005576</td>\n",
       "      <td>1.179809</td>\n",
       "      <td>Uncured Turkey Bologna</td>\n",
       "      <td>Gluten Free Organic Cereal Coconut Maple Vanilla</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   antecedents consequents  antecedent support  consequent support   support  \\\n",
       "34       (211)       (110)            0.028126            0.037646  0.006635   \n",
       "35       (110)       (211)            0.037646            0.028126  0.006635   \n",
       "\n",
       "    confidence      lift  leverage  conviction  \\\n",
       "34    0.235897  6.266195  0.005576    1.259457   \n",
       "35    0.176245  6.266195  0.005576    1.179809   \n",
       "\n",
       "                                    antecedents_name  \\\n",
       "34  Gluten Free Organic Cereal Coconut Maple Vanilla   \n",
       "35                            Uncured Turkey Bologna   \n",
       "\n",
       "                                    consequents_name  \n",
       "34                            Uncured Turkey Bologna  \n",
       "35  Gluten Free Organic Cereal Coconut Maple Vanilla  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COLUNA MISSING\n",
    "\n",
    "url = r\"https://raw.githubusercontent.com/brvnl/AplicacoesAprendizadoMaquina/main/order_products__train.csv\"\n",
    "df_raw = pd.read_csv(url, usecols=[\"order_id\", \"product_id\"])\n",
    "\n",
    "# Ex1.: Procurando relações entre produtos nos departamentos \"personal care\", \"meat seafood\", \"missing\"\n",
    "df_raw = filter_aisle_department(df_raw, aisle = None, department = [\"missing\"])\n",
    "df_raw[\"comprado\"] = 1\n",
    "\n",
    "# Caso os dados já estejam previamente filtrados podemos usar o dataframe diretamente\n",
    "df1 = df_raw.pivot_table(index='order_id', columns='product_id', values=\"comprado\", fill_value=0)\n",
    "\n",
    "\n",
    "# Acha os conjuntos frequentes que atendem um suporte minimo (%)\n",
    "frequent_itemsets = apriori(df1, min_support=0.0006)\n",
    "\n",
    "# Filtra os conjuntos pela métrica confiança\n",
    "if len(frequent_itemsets):\n",
    "    selected = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.02)\n",
    "else:\n",
    "    print(\"Não há itemsets que atendam ao mínimo suporte fornecido.\")\n",
    "    \n",
    "if len(frequent_itemsets):\n",
    "    selected[\"antecedents_name\"] = selected[\"antecedents\"].apply(int_from_frozenset)\n",
    "    selected[\"consequents_name\"] = selected[\"consequents\"].apply(int_from_frozenset)\n",
    "    selected.drop(columns=[\"antecedents\", \"consequents\"])\n",
    "else:\n",
    "    print(\"Não há itemsets que atendam ao mínimo suporte fornecido.\")\n",
    "    \n",
    "\n",
    "selected[selected['support'] == max(selected['support'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantas compras diferentes? 14908.\n",
      "Quantos produtos diferentes? 4314.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-197-0adce3498d88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mselected\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mselected\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'support'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselected\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'support'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "# COLUNA \"personal care\"\n",
    "\n",
    "url = r\"https://raw.githubusercontent.com/brvnl/AplicacoesAprendizadoMaquina/main/order_products__train.csv\"\n",
    "df_raw = pd.read_csv(url, usecols=[\"order_id\", \"product_id\"])\n",
    "\n",
    "# Ex1.: Procurando relações entre produtos nos departamentos \"personal care\", \"meat seafood\", \"missing\"\n",
    "df_raw = filter_aisle_department(df_raw, aisle = None, department = [\"personal care\"])\n",
    "df_raw[\"comprado\"] = 1\n",
    "\n",
    "# Caso os dados já estejam previamente filtrados podemos usar o dataframe diretamente\n",
    "df1 = df_raw.pivot_table(index='order_id', columns='product_id', values=\"comprado\", fill_value=0)\n",
    "\n",
    "\n",
    "# Acha os conjuntos frequentes que atendem um suporte minimo (%)\n",
    "frequent_itemsets = apriori(df1, min_support=0.005)\n",
    "\n",
    "# Filtra os conjuntos pela métrica confiança\n",
    "if len(frequent_itemsets):\n",
    "    selected = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.02)\n",
    "else:\n",
    "    print(\"Não há itemsets que atendam ao mínimo suporte fornecido.\")\n",
    "    \n",
    "if len(frequent_itemsets):\n",
    "    selected[\"antecedents_name\"] = selected[\"antecedents\"].apply(int_from_frozenset)\n",
    "    selected[\"consequents_name\"] = selected[\"consequents\"].apply(int_from_frozenset)\n",
    "    selected.drop(columns=[\"antecedents\", \"consequents\"])\n",
    "else:\n",
    "    print(\"Não há itemsets que atendam ao mínimo suporte fornecido.\")\n",
    "    \n",
    "if len(selected):\n",
    "    selected[selected['support'] == max(selected['support'])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
