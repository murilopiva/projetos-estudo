{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP com Naive Bayes\n",
    "\n",
    "Apesar de ter algumas formas mais automáticas de fazer o que implementaremos a seguir, o objetivo de fazer tudo na 'unha', é justamente aprender como as coisas funcionam na representação de texto. Em seguida, para classificar, usaremos os recursos do Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "df = df.rename(columns={\"v2\" : \"text\", \"v1\":\"label\"})\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text Unnamed: 2  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1      ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3      ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "...    ...                                                ...        ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
       "5568   ham              Will Ì_ b going to esplanade fr home?        NaN   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n",
       "5571   ham                         Rofl. Its true to its name        NaN   \n",
       "\n",
       "     Unnamed: 3 Unnamed: 4  \n",
       "0           NaN        NaN  \n",
       "1           NaN        NaN  \n",
       "2           NaN        NaN  \n",
       "3           NaN        NaN  \n",
       "4           NaN        NaN  \n",
       "...         ...        ...  \n",
       "5567        NaN        NaN  \n",
       "5568        NaN        NaN  \n",
       "5569        NaN        NaN  \n",
       "5570        NaN        NaN  \n",
       "5571        NaN        NaN  \n",
       "\n",
       "[5572 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "Ok lar... Joking wif u oni...\n",
      "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "U dun say so early hor... U c already then say...\n",
      "Nah I don't think he goes to usf, he lives around here though\n"
     ]
    }
   ],
   "source": [
    "# vamos pegar as primeiras linhas\n",
    "\n",
    "textos = list(df['text'][:5])\n",
    "for t in textos:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Go', 'until', 'jurong', 'point,', 'crazy..', 'Available', 'only', 'in', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet...', 'Cine', 'there', 'got', 'amore', 'wat...']\n"
     ]
    }
   ],
   "source": [
    "# vamos quebrar a primeira linha em palavras\n",
    "\n",
    "print(textos[0].split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['go', 'until', 'jurong', 'point,', 'crazy', 'available', 'only', 'in', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet', 'cine', 'there', 'got', 'amore', 'wat', 'ok', 'lar', 'joking', 'wif', 'u', 'oni', 'free', 'entry', '2', 'a', 'wkly', 'comp', 'to', 'win', 'fa', 'cup', 'final', 'tkts', '21st', 'may', '2005', 'text', '87121', 'receive', 'question(std', 'txt', \"rate)t&c's\", 'apply', \"08452810075over18's\", 'dun', 'say', 'so', 'early', 'hor', 'c', 'already', 'then', 'nah', 'i', \"don't\", 'think', 'he', 'goes', 'usf,', 'lives', 'around', 'here', 'though']\n"
     ]
    }
   ],
   "source": [
    "# agora, vamos pegar todas as palavras das cinco amostras e criar um vocabulário, evitando as repetições\n",
    "vocabulario = []\n",
    "for t in textos:\n",
    "    palavras = t.lower().replace('.','').split()\n",
    "    for p in palavras:\n",
    "        if p not in vocabulario:\n",
    "            vocabulario.append(p)\n",
    "            \n",
    "print(vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    }
   ],
   "source": [
    "# vamos verificar o tamanho do vocabulario\n",
    "\n",
    "print(len(vocabulario))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agora é necessário representar cada frase usando o vocabulário\n",
    "\n",
    "textos = list(df['text'])\n",
    "amostras = []\n",
    "for t in textos:\n",
    "    amostra = []\n",
    "    for p in vocabulario:\n",
    "        if p in t.lower().replace('.','').split():\n",
    "            amostra.append(1)\n",
    "        else:\n",
    "            amostra.append(0)\n",
    "            \n",
    "    amostras.append(amostra)\n",
    "    \n",
    "amostras = np.array(amostras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "go 1\n",
      "until 1\n",
      "jurong 1\n",
      "point, 1\n",
      "crazy 1\n",
      "available 1\n",
      "only 1\n",
      "in 1\n",
      "bugis 1\n",
      "n 1\n",
      "great 1\n",
      "world 1\n",
      "la 1\n",
      "e 1\n",
      "buffet 1\n",
      "cine 1\n",
      "there 1\n",
      "got 1\n",
      "amore 1\n",
      "wat 1\n",
      "ok 0\n",
      "lar 0\n",
      "joking 0\n",
      "wif 0\n",
      "u 0\n",
      "oni 0\n",
      "free 0\n",
      "entry 0\n",
      "2 0\n",
      "a 0\n",
      "wkly 0\n",
      "comp 0\n",
      "to 0\n",
      "win 0\n",
      "fa 0\n",
      "cup 0\n",
      "final 0\n",
      "tkts 0\n",
      "21st 0\n",
      "may 0\n",
      "2005 0\n",
      "text 0\n",
      "87121 0\n",
      "receive 0\n",
      "question(std 0\n",
      "txt 0\n",
      "rate)t&c's 0\n",
      "apply 0\n",
      "08452810075over18's 0\n",
      "dun 0\n",
      "say 0\n",
      "so 0\n",
      "early 0\n",
      "hor 0\n",
      "c 0\n",
      "already 0\n",
      "then 0\n",
      "nah 0\n",
      "i 0\n",
      "don't 0\n",
      "think 0\n",
      "he 0\n",
      "goes 0\n",
      "usf, 0\n",
      "lives 0\n",
      "around 0\n",
      "here 0\n",
      "though 0\n"
     ]
    }
   ],
   "source": [
    "#amostras[0]\n",
    "print(textos[0])\n",
    "for p, a in zip(vocabulario, amostras[0]):\n",
    "    print(p, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separação de dados e treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos separar os dados em 33% pra teste e com semente aleatória fixa em 42\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(amostras, df['label'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9157150625339858\n"
     ]
    }
   ],
   "source": [
    "# temos 3 modelos, vamos avaliar diferentes cenários e observar os resultados\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = BernoulliNB()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'spam']\n",
      "go \t\t -3.039903491867129 -3.164067588373206\n",
      "until \t\t -5.5183792513248395 -5.109977737428519\n",
      "jurong \t\t -7.39018142822643 -6.208590026096629\n",
      "point, \t\t -7.39018142822643 -6.208590026096629\n",
      "crazy \t\t -6.00388706710654 -5.109977737428519\n",
      "available \t\t -6.00388706710654 -5.109977737428519\n",
      "only \t\t -3.6888794541139367 -2.296567020668483\n",
      "in \t\t -1.884849892294068 -2.4019275363263093\n",
      "bugis \t\t -6.137418459731062 -6.208590026096629\n",
      "n \t\t -3.8206487317450604 -3.906004933102583\n",
      "great \t\t -4.233181007076317 -4.01136544876041\n",
      "world \t\t -5.138889629619936 -5.5154428455366835\n",
      "la \t\t -6.697034247666485 -6.208590026096629\n",
      "e \t\t -4.299138974868114 -4.822295664976738\n",
      "buffet \t\t -6.984716320118266 -6.208590026096629\n",
      "cine \t\t -6.291569139558321 -6.208590026096629\n",
      "there \t\t -3.458355795502105 -4.129148484416794\n",
      "got \t\t -3.141686186177072 -4.2626798770413155\n",
      "amore \t\t -7.39018142822643 -6.208590026096629\n",
      "wat \t\t -4.212127597878485 -5.5154428455366835\n",
      "ok \t\t -3.0463760063727463 -4.599152113662528\n",
      "lar \t\t -4.716032778799901 -6.208590026096629\n",
      "joking \t\t -6.697034247666485 -6.208590026096629\n",
      "wif \t\t -5.138889629619936 -6.208590026096629\n",
      "u \t\t -1.9988291957112043 -1.8911019125603188\n",
      "oni \t\t -6.697034247666485 -6.208590026096629\n",
      "free \t\t -4.39444915467244 -1.5357611916347231\n",
      "entry \t\t -8.083328608786376 -3.3753766820404127\n",
      "2 \t\t -2.971340820429832 -1.6977305195797792\n",
      "a \t\t -1.718577851934465 -0.9203229954020937\n",
      "wkly \t\t -8.083328608786376 -3.8106947532982582\n",
      "comp \t\t -7.39018142822643 -4.01136544876041\n",
      "to \t\t -1.324073338122683 -0.468797113917395\n",
      "win \t\t -6.473890696352275 -2.5450283799669826\n",
      "fa \t\t -8.083328608786376 -5.5154428455366835\n",
      "cup \t\t -7.39018142822643 -4.599152113662528\n",
      "final \t\t -7.39018142822643 -3.906004933102583\n",
      "tkts \t\t -8.083328608786376 -4.822295664976738\n",
      "21st \t\t -7.39018142822643 -5.5154428455366835\n",
      "may \t\t -4.947834392857226 -4.599152113662528\n",
      "2005 \t\t -8.083328608786376 -5.5154428455366835\n",
      "text \t\t -4.171305603358229 -2.0189352840702037\n",
      "87121 \t\t -8.083328608786376 -4.822295664976738\n",
      "receive \t\t -6.697034247666485 -3.0730958101674792\n",
      "question(std \t\t -8.083328608786376 -5.5154428455366835\n",
      "txt \t\t -5.598421958998376 -1.7542427298431216\n",
      "rate)t&c's \t\t -8.083328608786376 -5.5154428455366835\n",
      "apply \t\t -8.083328608786376 -3.0730958101674792\n",
      "08452810075over18's \t\t -8.083328608786376 -5.5154428455366835\n",
      "dun \t\t -4.586821047319896 -6.208590026096629\n",
      "say \t\t -4.005791164880656 -6.208590026096629\n",
      "so \t\t -2.50737950564006 -3.643640668635092\n",
      "early \t\t -4.9052747784384305 -6.208590026096629\n",
      "hor \t\t -7.39018142822643 -6.208590026096629\n",
      "c \t\t -4.322128493092814 -3.7236833763086286\n",
      "already \t\t -4.233181007076317 -5.5154428455366835\n",
      "then \t\t -3.0997219870780395 -4.2626798770413155\n",
      "nah \t\t -6.291569139558321 -6.208590026096629\n",
      "i \t\t -1.0958383617853853 -3.117547572738313\n",
      "don't \t\t -3.7792635155822056 -5.109977737428519\n",
      "think \t\t -3.6766093615221225 -5.109977737428519\n",
      "he \t\t -3.594692239054236 -6.208590026096629\n",
      "goes \t\t -5.192956850890211 -6.208590026096629\n",
      "usf, \t\t -6.984716320118266 -6.208590026096629\n",
      "lives \t\t -6.697034247666485 -6.208590026096629\n",
      "around \t\t -4.499809670330266 -5.109977737428519\n",
      "here \t\t -3.9724547446130645 -5.5154428455366835\n",
      "though \t\t -5.375278407684165 -6.208590026096629\n"
     ]
    }
   ],
   "source": [
    "# vamos explorar o que o modelo armazenou de informação\n",
    "\n",
    "print(model.classes_)\n",
    "prob = model.feature_log_prob_\n",
    "\n",
    "for idx, p in enumerate(vocabulario):\n",
    "    print(p,'\\t\\t',prob[0][idx],prob[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['ham']\n",
      "[[0.99815635 0.00184365]]\n"
     ]
    }
   ],
   "source": [
    "# como testar com uma amostra nova\n",
    "\n",
    "amostra_nova = 'Ok lar... Joking wif u oni...'\n",
    "amostra = []\n",
    "for p in vocabulario:\n",
    "    if p in amostra_nova.lower().replace('.','').split():\n",
    "        amostra.append(1)\n",
    "    else:\n",
    "        amostra.append(0)\n",
    "            \n",
    "print(amostra)\n",
    "\n",
    "print(model.predict([amostra]))\n",
    "print(model.predict_proba([amostra]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício\n",
    "\n",
    "Aumente a quantidade de amostras utilizadas para montar o vocabulário e avalie se o resultado melhora ou piora. Crie uma tabela comparativa com os 3 métodos (colunas) de Naive Bayes do Scikit-Learn e avalie diferentes tamanhos de vocabulário (linhas). Faça isso em um arquivo a parte, com seu nome no cabeçalho do documento, o código necessário do experimento e, ao final, a tabela contend os resultados, e sua conclusão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
