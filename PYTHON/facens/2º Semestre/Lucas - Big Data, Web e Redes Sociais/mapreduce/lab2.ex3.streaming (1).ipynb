{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício Prático"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faça o download do data set ml-100k do movielens e importe dentro da pasta resources. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crie uma pasta com o seu nome dentro de /user no HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml-latest-small.zip 100%[===================>] 955.28K   918KB/s    in 1.0s    \n",
      "Archive:  ml-latest-small.zip\n",
      "   creating: ml-latest-small/\n",
      "  inflating: ml-latest-small/links.csv  \n",
      "  inflating: ml-latest-small/tags.csv  \n",
      "  inflating: ml-latest-small/ratings.csv  \n",
      "  inflating: ml-latest-small/README.txt  \n",
      "  inflating: ml-latest-small/movies.csv  \n"
     ]
    }
   ],
   "source": [
    "!wget http://files.grouplens.org/datasets/movielens/ml-latest-small.zip -q --show-progress\n",
    "!unzip ml-latest-small.zip\n",
    "!rm ml-latest-small.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DATASET_PATH=ml-latest-small\n"
     ]
    }
   ],
   "source": [
    "%env DATASET_PATH ml-latest-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3.2M\n",
      "drwxr-xr-x 2 jovyan root   4.0K Sep 26  2018 .\n",
      "drwxr-xr-x 1 jovyan jovyan 4.0K Sep 24 23:01 ..\n",
      "-rw-r--r-- 1 jovyan root   194K Sep 26  2018 links.csv\n",
      "-rw-r--r-- 1 jovyan root   483K Sep 26  2018 movies.csv\n",
      "-rw-r--r-- 1 jovyan root   2.4M Sep 26  2018 ratings.csv\n",
      "-rw-r--r-- 1 jovyan root   8.2K Sep 26  2018 README.txt\n",
      "-rw-r--r-- 1 jovyan root   116K Sep 26  2018 tags.csv\n"
     ]
    }
   ],
   "source": [
    "!ls ${DATASET_PATH} -lha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "drwxr-xr-x   - jovyan supergroup          0 2020-09-24 22:43 /hbase\n",
      "drwxrwxr-x   - jovyan supergroup          0 2020-09-24 22:42 /tmp\n",
      "drwxr-xr-x   - jovyan supergroup          0 2020-09-24 22:48 /user\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -mkdir /user/murilo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "drwxr-xr-x   - jovyan supergroup          0 2020-09-24 22:42 /user/hive\n",
      "drwxr-xr-x   - jovyan supergroup          0 2020-09-24 22:42 /user/jovyan\n",
      "drwxr-xr-x   - jovyan supergroup          0 2020-09-24 22:48 /user/murilo\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copie para o HDFS, dentro da pasta com seu nome, o arquivo que possui os ratings dos usuários para os filmes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -copyFromLocal ${DATASET_PATH}/ratings.csv /user/murilo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "-rw-r--r--   1 jovyan supergroup    2483723 2020-09-24 23:04 /user/murilo/ratings.csv\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/murilo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilize MapReduce para responder às perguntas abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qual a quantidade de ratings para cada nível? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute o seu código no sistema de arquivos local e no HDFS -- utilize Hadoop Streaming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/resources/local/hadoop-2.9.2/share/hadoop/tools/sources/hadoop-streaming-2.9.2-sources.jar\n",
      "/home/jovyan/resources/local/hadoop-2.9.2/share/hadoop/tools/sources/hadoop-streaming-2.9.2-test-sources.jar\n",
      "/home/jovyan/resources/local/hadoop-2.9.2/share/hadoop/tools/lib/hadoop-streaming-2.9.2.jar\n"
     ]
    }
   ],
   "source": [
    "!find $HOME/ -name hadoop-streaming*.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /user/murilo/output/_SUCCESS\n",
      "Deleted /user/murilo/output/part-00000\n",
      "packageJobJar: [/tmp/hadoop-unjar6143247490730750364/] [] /tmp/streamjob2733331306892472727.jar tmpDir=null\n",
      "20/09/25 00:15:24 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "20/09/25 00:15:25 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "20/09/25 00:15:25 INFO mapred.FileInputFormat: Total input files to process : 1\n",
      "20/09/25 00:15:25 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "20/09/25 00:15:25 INFO Configuration.deprecation: yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled\n",
      "20/09/25 00:15:25 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1600987335947_0009\n",
      "20/09/25 00:15:26 INFO impl.YarnClientImpl: Submitted application application_1600987335947_0009\n",
      "20/09/25 00:15:26 INFO mapreduce.Job: The url to track the job: http://jupyter-thedatasociety-2dlab-2dhadoop-2di77mtacu:8088/proxy/application_1600987335947_0009/\n",
      "20/09/25 00:15:26 INFO mapreduce.Job: Running job: job_1600987335947_0009\n",
      "20/09/25 00:15:40 INFO mapreduce.Job: Job job_1600987335947_0009 running in uber mode : false\n",
      "20/09/25 00:15:40 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "20/09/25 00:15:49 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "20/09/25 00:16:01 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "20/09/25 00:16:02 INFO mapreduce.Job: Job job_1600987335947_0009 completed successfully\n",
      "20/09/25 00:16:02 INFO mapreduce.Job: Counters: 49\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1411727\n",
      "\t\tFILE: Number of bytes written=3425412\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=2487240\n",
      "\t\tHDFS: Number of bytes written=169\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=2\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=14723\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=9249\n",
      "\t\tTotal time spent by all map tasks (ms)=14723\n",
      "\t\tTotal time spent by all reduce tasks (ms)=9249\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=14723\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=9249\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=15076352\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=9470976\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=100837\n",
      "\t\tMap output records=100837\n",
      "\t\tMap output bytes=1210047\n",
      "\t\tMap output materialized bytes=1411733\n",
      "\t\tInput split bytes=194\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=11\n",
      "\t\tReduce shuffle bytes=1411733\n",
      "\t\tReduce input records=100837\n",
      "\t\tReduce output records=11\n",
      "\t\tSpilled Records=201674\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=854\n",
      "\t\tCPU time spent (ms)=4810\n",
      "\t\tPhysical memory (bytes) snapshot=756498432\n",
      "\t\tVirtual memory (bytes) snapshot=5758283776\n",
      "\t\tTotal committed heap usage (bytes)=499646464\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2487046\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=169\n",
      "20/09/25 00:16:02 INFO streaming.StreamJob: Output directory: /user/murilo/output\n"
     ]
    }
   ],
   "source": [
    "# !cat ./resources/datasets/animals.txt | python resources/mappers/mapper1.py | sort -k1,1 | python resources/reducers/reducer1.py\n",
    "!hdfs dfs -rm /user/murilo/output/*\n",
    "!hdfs dfs -rmdir /user/murilo/output/\n",
    "\n",
    "!hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-2.9.2.jar \\\n",
    "-input   /user/murilo/ratings.csv \\\n",
    "-output  /user/murilo/output \\\n",
    "-mapper  \"python $(pwd)/resources/mappers/mapper1.py\" \\\n",
    "-reducer \"python $(pwd)/resources/reducers/reducer1.py\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `/user/murilo/output/_temporary': Is a directory\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   1 jovyan supergroup          0 2020-09-24 23:48 /user/murilo/output/_SUCCESS\n",
      "-rw-r--r--   1 jovyan supergroup    2584560 2020-09-24 23:48 /user/murilo/output/part-00000\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/murilo/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nivel 0.5\t1370\n",
      "nivel 1.0\t2811\n",
      "nivel 1.5\t1791\n",
      "nivel 2.0\t7551\n",
      "nivel 2.5\t5550\n",
      "nivel 3.0\t20047\n",
      "nivel 3.5\t13136\n",
      "nivel 4.0\t26818\n",
      "nivel 4.5\t8551\n",
      "nivel 5.0\t13211\n",
      "nivel rating\t1\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -tail /user/murilo/output/part-00000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qual a popularidade de cada filme?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute o seu código no sistema de arquivos local e no HDFS -- utilize Hadoop Streaming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /user/murilo/outputEx2/_SUCCESS\n",
      "Deleted /user/murilo/outputEx2/part-00000\n",
      "packageJobJar: [/tmp/hadoop-unjar2234315130812889202/] [] /tmp/streamjob1998187796857259312.jar tmpDir=null\n",
      "20/09/25 00:26:58 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "20/09/25 00:26:59 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "20/09/25 00:26:59 INFO mapred.FileInputFormat: Total input files to process : 1\n",
      "20/09/25 00:27:00 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "20/09/25 00:27:00 INFO Configuration.deprecation: yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled\n",
      "20/09/25 00:27:00 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1600987335947_0011\n",
      "20/09/25 00:27:00 INFO impl.YarnClientImpl: Submitted application application_1600987335947_0011\n",
      "20/09/25 00:27:01 INFO mapreduce.Job: The url to track the job: http://jupyter-thedatasociety-2dlab-2dhadoop-2di77mtacu:8088/proxy/application_1600987335947_0011/\n",
      "20/09/25 00:27:01 INFO mapreduce.Job: Running job: job_1600987335947_0011\n",
      "20/09/25 00:27:17 INFO mapreduce.Job: Job job_1600987335947_0011 running in uber mode : false\n",
      "20/09/25 00:27:17 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "20/09/25 00:27:39 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "20/09/25 00:27:55 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "20/09/25 00:27:56 INFO mapreduce.Job: Job job_1600987335947_0011 completed successfully\n",
      "20/09/25 00:27:56 INFO mapreduce.Job: Counters: 50\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1515448\n",
      "\t\tFILE: Number of bytes written=3632863\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=2487240\n",
      "\t\tHDFS: Number of bytes written=133967\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tKilled map tasks=1\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=2\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=31737\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=9994\n",
      "\t\tTotal time spent by all map tasks (ms)=31737\n",
      "\t\tTotal time spent by all reduce tasks (ms)=9994\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=31737\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=9994\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=32498688\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=10233856\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=100837\n",
      "\t\tMap output records=100837\n",
      "\t\tMap output bytes=1313768\n",
      "\t\tMap output materialized bytes=1515454\n",
      "\t\tInput split bytes=194\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=9725\n",
      "\t\tReduce shuffle bytes=1515454\n",
      "\t\tReduce input records=100837\n",
      "\t\tReduce output records=9725\n",
      "\t\tSpilled Records=201674\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=613\n",
      "\t\tCPU time spent (ms)=5330\n",
      "\t\tPhysical memory (bytes) snapshot=745738240\n",
      "\t\tVirtual memory (bytes) snapshot=5751971840\n",
      "\t\tTotal committed heap usage (bytes)=501743616\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2487046\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=133967\n",
      "20/09/25 00:27:56 INFO streaming.StreamJob: Output directory: /user/murilo/outputEx2\n"
     ]
    }
   ],
   "source": [
    "# !cat ./resources/datasets/animals.txt | python resources/mappers/mapper1.py | sort -k1,1 | python resources/reducers/reducer1.py\n",
    "!hdfs dfs -rm /user/murilo/outputEx2/*\n",
    "!hdfs dfs -rmdir /user/murilo/outputEx2/\n",
    "\n",
    "!hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-2.9.2.jar \\\n",
    "-input   /user/murilo/ratings.csv \\\n",
    "-output  /user/murilo/outputEx2 \\\n",
    "-mapper  \"python $(pwd)/resources/mappers/mapper2.py\" \\\n",
    "-reducer \"python $(pwd)/resources/reducers/reducer1.py\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t31\n",
      "nivel 97950\t1\n",
      "nivel 97988\t1\n",
      "nivel 98061\t1\n",
      "nivel 98083\t2\n",
      "nivel 981\t2\n",
      "nivel 98122\t2\n",
      "nivel 98124\t7\n",
      "nivel 98154\t4\n",
      "nivel 98160\t1\n",
      "nivel 98175\t1\n",
      "nivel 982\t1\n",
      "nivel 98203\t4\n",
      "nivel 98230\t1\n",
      "nivel 98239\t2\n",
      "nivel 98243\t12\n",
      "nivel 98279\t2\n",
      "nivel 98296\t1\n",
      "nivel 98361\t1\n",
      "nivel 984\t2\n",
      "nivel 98491\t8\n",
      "nivel 98499\t2\n",
      "nivel 98503\t1\n",
      "nivel 98585\t5\n",
      "nivel 986\t13\n",
      "nivel 98604\t1\n",
      "nivel 98607\t1\n",
      "nivel 98623\t2\n",
      "nivel 98633\t1\n",
      "nivel 98697\t1\n",
      "nivel 987\t1\n",
      "nivel 98799\t1\n",
      "nivel 988\t2\n",
      "nivel 98809\t40\n",
      "nivel 98836\t1\n",
      "nivel 98908\t1\n",
      "nivel 98961\t14\n",
      "nivel 99\t2\n",
      "nivel 990\t5\n",
      "nivel 99005\t1\n",
      "nivel 99007\t14\n",
      "nivel 99030\t1\n",
      "nivel 99087\t1\n",
      "nivel 991\t11\n",
      "nivel 99106\t3\n",
      "nivel 99112\t12\n",
      "nivel 99114\t71\n",
      "nivel 99117\t8\n",
      "nivel 99122\t1\n",
      "nivel 99130\t1\n",
      "nivel 99145\t3\n",
      "nivel 99149\t7\n",
      "nivel 99191\t1\n",
      "nivel 993\t1\n",
      "nivel 994\t11\n",
      "nivel 99415\t1\n",
      "nivel 99437\t2\n",
      "nivel 99532\t2\n",
      "nivel 99574\t1\n",
      "nivel 996\t13\n",
      "nivel 99636\t1\n",
      "nivel 99638\t1\n",
      "nivel 99721\t1\n",
      "nivel 99728\t3\n",
      "nivel 99750\t1\n",
      "nivel 99764\t2\n",
      "nivel 998\t3\n",
      "nivel 99813\t8\n",
      "nivel 99846\t1\n",
      "nivel 99853\t1\n",
      "nivel 999\t12\n",
      "nivel 99910\t2\n",
      "nivel 99917\t3\n",
      "nivel 99992\t1\n",
      "nivel movieId\t1\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -tail /user/murilo/outputEx2/part-00000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
