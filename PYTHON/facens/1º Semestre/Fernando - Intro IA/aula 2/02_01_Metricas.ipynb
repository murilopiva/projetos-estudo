{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c7b58b500e937f7d0f80b1920b86b86d054634e7"
   },
   "source": [
    "## Métricas de desempenho\n",
    "\n",
    "As métricas de desempenho auxiliam a entender como um determinado se comporta ao identificar padrões de um conjunto de dados. Nem sempre identificar apenas a acurácia de um problema é suficiente. Muitas vezes é necessário identificar se a classe crítica de um problema (quando houver) está sendo considerada na escolha de um modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "Utilizando o conjunto de dados de câncer de mama, o objetivo deste notebook é avaliar as métricas de desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "bc = load_breast_cancer()\n",
    "\n",
    "data = bc.data\n",
    "target = bc.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(569, 30)\n"
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0 1]\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.unique(target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente, é necessário criar uma divisão dos dados em treino e teste para analisar o desempenho de algum método de classificação através de alguma métrica. Para isso, considere a divisão de 33% para teste e o método de classificação k-NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "_uuid": "90beb882502d5f323484877012f765f1c0b230c5"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n                     weights='uniform')"
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "# separando os dados em treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.33, random_state=42)\n",
    "\n",
    "# treinando o modelo \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após o treinamento, as métricas de desempenho são obtidas ao analisar amostra por amostra a relação entre o rótulo conhecido (y_train ou y_test) e o rótulo informado (y_pred) pelo método de classificação. Para identificar a acurácia, basta encontrar a relação de rótulos corretamente predizidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "_uuid": "b30dbc5b4a5cc978cca307647fe6d0ebcd0939b9",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Acurácia: 0.9308510638297872\nAcurácia: 0.9308510638297872\nAcurácia: 0.9308510638297872\n"
    }
   ],
   "source": [
    "# predizendo os rótulos com o modelo\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# calculando a acurácia sem scikit-learn\n",
    "certos = 0\n",
    "\n",
    "for idx, rotulo in enumerate(y_pred):\n",
    "    if rotulo == y_test[idx]:\n",
    "        certos += 1\n",
    "\n",
    "print('Acurácia:', certos/y_pred.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "# calculando a acurácia de forma vetorizada\n",
    "certos = np.sum(y_test == y_pred)\n",
    "\n",
    "print('Acurácia:', certos/y_pred.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "# avaliando o modelo com o scikit-learn\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Acurácia:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algumas informações a mais sobre o desempenho do modelo podem ser extraídas da matriz de confusão, que traça a relação mais precisa dos erros do modelo. Assim, em vez de simplesmente observar quando um rótulo foi corretamente predizido, registra-se também quando houve erros e quais classes foram mais confundidas. \n",
    "\n",
    "\n",
    "A matriz de confusão é criada a partir da relação entre os rótulos de referências e os rótulos dados pelo modelo. Um problema de classificação binário, portanto, terá informações a respeito das amostras rotuladas corretamente (verdadeiros positivos e negativos) e das amostras que confundiram o modelo (falsos positivos e negativos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "_uuid": "215594583e93cda8d295411b27b1a49f4331da2c",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "VP: 114\nFP: 6\nVN: 61\nFN: 7\n---\n[[ 61   6]\n [  7 114]]\n---\nVP: 114\nFP: 6\nVN: 61\nFN: 7\n"
    }
   ],
   "source": [
    "# predizendo os rótulos a partir do modelo\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# vp = verdadeiros positivos\n",
    "# vn = verdadeiros negativos\n",
    "# fp = falsos positivos\n",
    "# fn = falsos negativos\n",
    "\n",
    "vp = 0\n",
    "vn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "\n",
    "for pred, true in zip(y_pred, y_test):\n",
    "    if pred == 1:\n",
    "        if pred == true:\n",
    "            vp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    else:\n",
    "        if pred == true:\n",
    "            vn += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "\n",
    "print('VP:', vp)\n",
    "print('FP:', fp)\n",
    "print('VN:', vn)\n",
    "print('FN:', fn)\n",
    "\n",
    "print('---')\n",
    "\n",
    "# calculando a matriz utilizando scikit-learn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print('---')\n",
    "\n",
    "# obtendo os resultados com scikit-learn\n",
    "vn, fp, fn, vp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print('VP:', vp)\n",
    "print('FP:', fp)\n",
    "print('VN:', vn)\n",
    "print('FN:', fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir dos resultados é possível perceber que o número de verdadeiros positivos e negativos é maior do que as ocorrências de falsos. Isso é um resultado bom para o modelo. As informações dos erros, ou falsos positivos e negativos, ajuda a monitorar como o modelo erra e qual classe ele mais confunde. Em cima disso, decisões podem ser tomadas. Por exemplo, pode-se optar por um modelo que erra mais uma classe do que outra, como em problemas com classes críticas.\n",
    "\n",
    "No problema abordado nesse notebook, do câncer de mama, existe uma classe crítica. É preferível um modelo que tenha taxa maior de falsos positivos ou falsos negativos? Certamente que os falsos negativos são mais prejudiciais (um laudo que dá resultado negativo para uma pessoa que tem câncer). Uma forma de analisar a qualidade desse modelo considerando a classe crítica é através da revocação.\n",
    "\n",
    "A revocação encontra a relação de todos verdadeiros positivos com os verdadeiros positivos e falsos negativos. Quanto menos falsos negativos um modelo tiver de resultado, maior será a revocação. No entanto, deve-se tomar cuidado com uma revocação muito alta que gera um modelo inútil. Por exemplo, um modelo que classifica tudo como positivo sempre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Seguindo a fórmula dos slides, calcule as medidas de precisão, revocação e f-medida utilizando as informações da matriz de confusão. Se preferir, crie uma função para isso, pois será útil para o exercício seguinte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.95\n0.9421487603305785\n0.946058091286307\n"
    }
   ],
   "source": [
    "\"\"\"\n",
    "p = vp / (vp + fp)\n",
    "r = vp / (vp + fn)\n",
    "fm = 2 * (p * r / (p + r))\n",
    "\"\"\"\n",
    "def prec(vp, fp):\n",
    "    return vp / (vp+fp)\n",
    "\n",
    "def recall (vp, fn):\n",
    "    return vp / (vp+fn)\n",
    "\n",
    "def fm (p, r):\n",
    "    return 2 * ((p * r) / (p+r))\n",
    "\n",
    "p = prec(vp,fp)\n",
    "r = recall(vp,fn)\n",
    "fm = fm(p,r)\n",
    "\n",
    "print (p)\n",
    "print (r)\n",
    "print (fm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e8240c0485b01f706d7d2f2476c2056614c0cf0f"
   },
   "source": [
    "(2) Utilizando o conjunto de dados do câncer de mama, avalie os resultados obtidos no teste (em vez do treino, como foi feito até aqui) e verifique se consegue encontrar algum modelo melhor, considerando o conceito de revocação, variando os parâmetros do KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.9421487603305785\n0.8925619834710744\n0.9504132231404959\n0.9090909090909091\n0.9586776859504132\n0.9338842975206612\n0.9834710743801653\n0.9669421487603306\n0.9917355371900827\n0.9834710743801653\n0.9917355371900827\n0.9834710743801653\n0.9834710743801653\n0.9834710743801653\n\n 0.9834710743801653\n"
    }
   ],
   "source": [
    "# separando os dados em treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.33, random_state=42)\n",
    "\n",
    "# treinando o modelo \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "for i in range(1,15):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # predizendo os rótulos com o modelo\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    # calculando a matriz utilizando scikit-learn\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    #print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    vn, fp, fn, vp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "    r = recall(vp,fn)\n",
    "    best_r = r\n",
    "    best_n = i\n",
    "\n",
    "    print(r)\n",
    "\n",
    "    if r > best_r:\n",
    "        best_r = r\n",
    "        best_n = i\n",
    "        \n",
    "    \n",
    "\n",
    "print('\\n',best_r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n     classe1       0.90      0.91      0.90        67\n     classe2       0.95      0.94      0.95       121\n\n    accuracy                           0.93       188\n   macro avg       0.92      0.93      0.92       188\nweighted avg       0.93      0.93      0.93       188\n\n"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names = {'classe1','classe2'}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para conhecimento, depois considere pesquisar a função **classification_report** do Scikit-Learn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}