{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento é provavelmente a parte mais importante de ciência dos dados\n",
    "\n",
    "Ter dados representativos sem atributos faltantes é provavelmente o pote de ouro em ciência dos dados. É muito incomum que os dados do mundo real não apresentem anomalias seja da própria natureza ou sejam anomalias introduzidas no processo de medição e registro da observação (amostra).\n",
    "\n",
    "Esse notebook é voltado para como tratar dados mais complexos e transformar todas as informações em números que façam sentido para que o modelo seja capaz de traçar a relação entre atributos e classes. A seguir é oferecida uma pequena parcela de um conjunto de dados da empresa Porto Seguro, no qual uma competição foi aberta e os competidores foram desafiados a criar um modelo para prever se uma apólice teria um sinistro registrado ou não, indicando o uso do serviço.\n",
    "\n",
    "Algumas características sobre o nome das features:\n",
    "- O nome dos atributos indica o grupo ao qual pertence (ind, reg, car);\n",
    "- Os prefixos bin e cat indicam atributos binários e categóricos, respectivamente;\n",
    "- Atributos sem os prefixos citados podem ser ordinais ou contínuos;\n",
    "- Atributos com -1 indicam dado faltante (missing); e\n",
    "- A coluna 'target' indica se houve sinistro para apólice ou não."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('porto.csv')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um cuidado especial que precisa ser tomado ao analisar um conjunto de dados é observar a distribuição dos atributos, por exemplo, pelo comando *describe()*. **Os valores estão em uma mesma escala? Será necessário normalizá-los?** Essas são perguntas quem você deverá se fazer ao trabalhar com os dados.\n",
    "\n",
    "---\n",
    "\n",
    "Em sequência, é importante verificar se existem registros duplicados. Registros duplicados em uma mesma classe não são relevantes para a maioria dos métodos, e podem economizar processamento quando removidos. **Já registros duplicados com classes diferentes podem confundir praticamente todos os métodos, é extremamente importante removê-los.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Antes:', df.shape)\n",
    "df.drop_duplicates()\n",
    "print('Depois:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[:18000]\n",
    "test  = df[18000:]\n",
    "\n",
    "display(train.describe())\n",
    "display(test.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao trabalhar com as colunas (atributos), é interessante ter uma organização de que tipo de dado determinado atributo é, e para quais propósitos determinado atributo pode ser usado. Nesse sentido, seguindo o trabalho de https://www.kaggle.com/bertcarremans/data-preparation-exploration, vamos criar metadados para esse conjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for f in train.columns:\n",
    "    # definindo o uso (entre rótulo, id e atributos)\n",
    "    if f == 'target':\n",
    "        role = 'target' # rótulo\n",
    "    elif f == 'id':\n",
    "        role = 'id'\n",
    "    else:\n",
    "        role = 'input' # atributos\n",
    "         \n",
    "    # definindo o tipo do dado\n",
    "    if 'bin' in f or f == 'target':\n",
    "        level = 'binary'\n",
    "    elif 'cat' in f or f == 'id':\n",
    "        level = 'nominal'\n",
    "    elif train[f].dtype == float:\n",
    "        level = 'interval'\n",
    "    elif train[f].dtype == int:\n",
    "        level = 'ordinal'\n",
    "        \n",
    "    # mantem keep como verdadeiro pra tudo, exceto id\n",
    "    keep = True\n",
    "    if f == 'id':\n",
    "        keep = False\n",
    "    \n",
    "    # cria o tipo de dado\n",
    "    dtype = train[f].dtype\n",
    "    \n",
    "    # cria dicionário de metadados\n",
    "    f_dict = {\n",
    "        'varname': f,\n",
    "        'role': role,\n",
    "        'level': level,\n",
    "        'keep': keep,\n",
    "        'dtype': dtype\n",
    "    }\n",
    "    data.append(f_dict)\n",
    "    \n",
    "meta = pd.DataFrame(data, columns=['varname', 'role', 'level', 'keep', 'dtype'])\n",
    "meta.set_index('varname', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para visualizar o atributo e todos seus metadados, basta mostrar a variável meta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com essa estrutura de metadados, fica fácil consultar quais colunas quer se manter e que são nominais, por exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[(meta.level == 'nominal') & (meta.keep)].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da mesma forma, seria possível contar os atributos por tipo de uso e dado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'count' : meta.groupby(['role', 'level'])['role'].size()}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valores faltantes\n",
    "\n",
    "Conforme já mencionado, os valores faltantes são indicados por -1, então é importante saber quais colunas têm valores faltantes e em qual proporção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos_missing = []\n",
    "\n",
    "for f in train.columns:\n",
    "    missings = train[train[f] == -1][f].count()\n",
    "    if missings > 0:\n",
    "        atributos_missing.append(f)\n",
    "        missings_perc = missings/df.shape[0]\n",
    "        \n",
    "        print('Atributo {} tem {} amostras ({:.2%}) com valores faltantes'.format(f, missings, missings_perc))\n",
    "        \n",
    "print('No total, há {} atributos com valores faltantes'.format(len(atributos_missing)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duas estratégias podem ser optadas aqui: simplesmente remover o atributo ou tentar preenchê-lo de forma sintética. Preencher de forma sintética pode gerar uma falsa distribuição quando o número de atributos faltantes é muito alto. Quando este for o caso, é sempre seguro optar por remover o atributo inteiro. Também é importante lembrar que a estratégia de preenchimento deve ser coerente com o tipo de dado, por exemplo: **dados ordinais não devem ser preenchidos com média, nem dados contínuos com moda.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removendo ps_car_03_cat e ps_car_05_cat que tem muitos valores faltantes\n",
    "vars_to_drop = ['ps_car_03_cat', 'ps_car_05_cat']\n",
    "train = train.drop(vars_to_drop, axis=1)\n",
    "test = test.drop(vars_to_drop, axis=1)\n",
    "meta.loc[(vars_to_drop),'keep'] = False  # atualiza os metadados para ter como referência (processar o test depois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "media_imp = Imputer(missing_values=-1, strategy='mean', axis=0)\n",
    "moda_imp = Imputer(missing_values=-1, strategy='most_frequent', axis=0)\n",
    "\n",
    "train['ps_reg_03'] = media_imp.fit_transform(train[['ps_reg_03']]).ravel()\n",
    "train['ps_car_12'] = media_imp.fit_transform(train[['ps_car_12']]).ravel()\n",
    "train['ps_car_14'] = media_imp.fit_transform(train[['ps_car_14']]).ravel()\n",
    "train['ps_car_11'] = moda_imp.fit_transform(train[['ps_car_11']]).ravel()\n",
    "\n",
    "test['ps_reg_03'] = media_imp.fit_transform(test[['ps_reg_03']]).ravel()\n",
    "test['ps_car_12'] = media_imp.fit_transform(test[['ps_car_12']]).ravel()\n",
    "test['ps_car_14'] = media_imp.fit_transform(test[['ps_car_14']]).ravel()\n",
    "test['ps_car_11'] = moda_imp.fit_transform(test[['ps_car_11']]).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os atributos categóricos podem ser mantidos porque o número de valores faltantes não é expressivo. Inclusive, a estratégia de preenchimento dos **atributos categóricos** é sempre mais complexa. Esses atributos **não se beneficiam de medidas estatísticas** como moda e média, portanto essas medidas não servem para preenchê-los de forma sintética.\n",
    "\n",
    "---\n",
    "\n",
    "## One-hot encoding (ou dummy variables)\n",
    "\n",
    "Depois de ter tratado os dados faltantes, é importante que os dados ordinais tenham representação apropriada para o problema tratado. Se o dado não tem distância ou rankamento entre eles, cada valor de um atributo deve ser representado por um conjunto de atributos de mesma distância. *(Verificar slides desse encontro para que isso fique mais claro)*\n",
    "\n",
    "Os dados que precisam ser separados em mais dimensões já foram identificados como nominais no pré-processamento. É importante verificar se esses dados têm grande variedade de valores ou não, e aplicar essa separação apenas se for viável. Por exemplo, se um determinado atributo tem 300 valores, isso geraria 300 colunas novas. Isso só se justificaria se fosse uma base realmente grande e se houvesse uma correlação muito alta entre essa variedade de valores e a classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = meta[(meta.level == 'nominal') & (meta.keep)].index\n",
    "\n",
    "for f in v:\n",
    "    dist_values = train[f].value_counts().shape[0]\n",
    "    print('Atributo {} tem {} valores distintos'.format(f, dist_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos optar por manter todos atributos e, portanto, gerar o conjunto de atributos que os mantêm à mesma distância:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = meta[(meta.level == 'nominal') & (meta.keep)].index\n",
    "print('Antes do one-hot encoding tinha-se {} atributos'.format(train.shape[1]))\n",
    "train = pd.get_dummies(train, columns=v, drop_first=True)\n",
    "print('Depois do one-hot encoding tem-se {} atributos'.format(train.shape[1]))\n",
    "\n",
    "test = pd.get_dummies(test, columns=v, drop_first=True)\n",
    "missing_cols = set( train.columns ) - set( test.columns )\n",
    "for c in missing_cols:\n",
    "    test[c] = 0\n",
    "    \n",
    "train, test = train.align(test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depois de todo pré-processamento...\n",
    "\n",
    "É hora de verificar se tanto treino como teste têm o mesmo tamanho/formato, e aplicar um modelo de classificação já que esse é um problema desse tipo. Vale lembrar que o tamanho do treino e teste pode variar quando você estiver participando de outras competições ou explorando outros conjuntos de dados.\n",
    "\n",
    "Isso porque na maioria das competições não se tem o *target* do test. Estima-se uma resposta e submete ao Kaggle, por exemplo, para que ele verifique qual foi o resultado final. Então esse tamanho pode variar em 1 entre treino e teste. No nosso caso, como todos os dados vêm de uma mesma fonte para experimentos, é esperado que tenham a mesma quantidade de atributos ou colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['id', 'target'], axis=1)\n",
    "y_train = train['target']\n",
    "\n",
    "X_test  = test.drop(['id', 'target'], axis=1)\n",
    "y_test  = test['target']\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
